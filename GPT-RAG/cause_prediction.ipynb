{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e1cb59-cc05-4433-b9d3-9185982bd38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from key import OPENAI_KEY, LANGSMITH_KEY # Import your own keys\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a50191-723c-458e-b360-6ec89ec0a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = \"../data/text/Subtask_2_test.json\"\n",
    "anno = json.load(open(text_dir))\n",
    "video_captions = json.load(open(\"eval_proc_out.json\"))\n",
    "cause_windows = json.load(open(\"cause_windows.json\"))\n",
    "emotion_labels = json.load(open(\"emotion_eval_labelled.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7558e61c-f2c7-433a-bfa4-994c53618621",
   "metadata": {},
   "source": [
    "#### Postprocessing Emotion Labelled data to ensure valid emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb79336-0e84-43d5-bae6-6672576157ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"anger\", \"joy\", \"sadness\", \"surprise\", \"disgust\", \"fear\"]\n",
    "\n",
    "for a in anno:\n",
    "    a[\"emotion-cause_pairs\"] = []\n",
    "    emo_labels = emotion_labels[str(a[\"conversation_ID\"])][\"conversation\"]\n",
    "    for i, utt in enumerate(a[\"conversation\"]):\n",
    "        emo = \"neutral\"\n",
    "        try:\n",
    "            emo = emo_labels[i][\"emotion\"].lower()\n",
    "            if emo not in emotions: emo = \"neutral\"\n",
    "        except:\n",
    "            emo = \"neutral\"\n",
    "        utt[\"emotion\"] = emo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f7b2d-01f0-44b1-8054-b51ca25ead9f",
   "metadata": {},
   "source": [
    "#### Loading Cause index and Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34931e-acea-4179-a384-ebb2cfd81900",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [\"beg\", \"mid\", \"end\"]\n",
    "db_dict = {emo : {} for emo in emotions}\n",
    "for emo in emotions:\n",
    "    for p in pos:\n",
    "        db_dict[emo][p] = FAISS.load_local(f\"cause_windows/{emo}/{p}\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec7780-bfb6-40cd-b5e2-44aaad591a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_beg(convo: list, size:int = 3) -> list:\n",
    "    return deepcopy(convo[:size])\n",
    "\n",
    "def get_window_end(convo: list, size:int = 6) -> list:\n",
    "    return deepcopy(convo[-size:])\n",
    "\n",
    "def get_window_mid(convo:list, idx:int, prev_size:int = 5, next_size:int = 2) -> list:\n",
    "    return deepcopy(convo[max(0, idx-prev_size) : (idx+1) + next_size])\n",
    "\n",
    "def format_window(window: tuple, label:bool = False) -> str:\n",
    "    idx, window = window\n",
    "    utt_idx = idx\n",
    "    emo = None\n",
    "    speaker = None\n",
    "    out_str = \"\"\n",
    "\n",
    "    for i, utt in enumerate(window):\n",
    "        if idx == utt[\"utterance_ID\"]:\n",
    "            emo = utt[\"emotion\"]\n",
    "            speaker = utt[\"speaker\"]\n",
    "            out_str += f'{i+1}. {utt[\"speaker\"]}: {utt[\"text\"]}'\n",
    "            if label: out_str += f' [{emo}]\\n'\n",
    "            else: out_str += '\\n'\n",
    "            utt_idx = i+1\n",
    "        else:\n",
    "            out_str += f'{i+1}. {utt[\"speaker\"]}: {utt[\"text\"]}\\n'\n",
    "    \n",
    "    if label:\n",
    "        out_str += f\"\\nWhat are the causal utterances that trigger the emotion of {emo} in {speaker} in utterance {utt_idx}?\"\n",
    "    \n",
    "    return out_str, idx-utt_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a46bd8d-4e08-4d6d-a60c-16624b74064c",
   "metadata": {},
   "source": [
    "#### Prompts and RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be96e25-d356-47ca-a390-867d1e9775dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "explaination_text = \"\"\"\n",
    "You are an expert in analyzing conversations to extract the causes of emotions \n",
    "in particular utterances by speakers. You give definite confident answers only.\n",
    "\n",
    "Description of emotional causes:\n",
    "- Each utterance always has a reason of why it was said and why it had a particular emotion.\n",
    "- A cause is an utterance that comes before or after the particular utterance in question that best explains to be the reason behind the particular emotion.\n",
    "- The emotional utterance itself can be a cause of itself if its content ALSO best explains the reason for the particular emotion. \n",
    "- Sometimes the cause can be beyond the context of the conversation thus an utterance might have no cause within conversation\n",
    "- There can be multiple causes for an utterance.\n",
    "\n",
    "Here's a conversation:\n",
    "{conversation}\n",
    "\n",
    "Analyze and justify the above annotation concisely.\n",
    "\"\"\"\n",
    "\n",
    "cause_text = \"\"\"\n",
    "You are an expert in analyzing conversations to extract the causes of emotions \n",
    "in particular utterances by speakers. You give definite confident answers only.\n",
    "\n",
    "Description of emotional causes:\n",
    "- Each utterance always has a reason of why it was said and why it had a particular emotion.\n",
    "- A cause is an utterance that comes before or after the particular utterance in question that best explains to be the reason behind the particular emotion.\n",
    "- The emotional utterance itself can be a cause of itself if its content ALSO best explains the reason for the particular emotion. \n",
    "- Sometimes the cause can be beyond the context of the conversation thus an utterance might have no cause within conversation\n",
    "- There can be multiple causes for an utterance.\n",
    "\n",
    "Here are some examples of how to recgonize causes:\n",
    "Example 1:\n",
    "{example_1}\n",
    "\n",
    "Example 2:\n",
    "{example_2}\n",
    "\n",
    "Example 3:\n",
    "{example_3}\n",
    "\n",
    "Now, please recognize the causes in following conversation. Heres the context for the whole conversation:\n",
    "{scene}\n",
    "\n",
    "Conversation:\n",
    "{window}\n",
    "\"\"\"\n",
    "\n",
    "json_text = \"{prompt}\\n\\nReformat the text to JSON as {{'causes': [list of causal utterance numbers]}}. No plain text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824c21b-440a-447e-b438-51bf1b4ff206",
   "metadata": {},
   "outputs": [],
   "source": [
    "explaination_prompt = ChatPromptTemplate.from_template(explaination_text)\n",
    "cause_prompt = ChatPromptTemplate.from_template(cause_text)\n",
    "json_prompt = ChatPromptTemplate.from_template(json_text)\n",
    "\n",
    "explaination_pipeline = explaination_prompt | model | output_parser\n",
    "cause_chain = cause_prompt | model | output_parser\n",
    "cause_json_chain = (\n",
    "    {\"prompt\": cause_chain}\n",
    "    | json_prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468925d4-8838-439c-b0b2-d8ccf040de26",
   "metadata": {},
   "source": [
    "#### Getting Cause for all Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e6617-a5d6-4843-8950-59df92ac45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_eval_labelled = {}\n",
    "# cause_eval_labelled = json.load(open(\"cause_eval_labelled.json\")) # if resuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a33d0-8830-41c0-b1e5-2e4d6b631fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 10\n",
    "for k, a in enumerate(anno):\n",
    "    conv_idx = a[\"conversation_ID\"]\n",
    "    convo = a[\"conversation\"]\n",
    "    for i, utt in enumerate(convo):\n",
    "        emo = utt[\"emotion\"]\n",
    "        utt_idx = utt[\"utterance_ID\"]\n",
    "        name = f\"dia{conv_idx}utt{utt_idx}\"\n",
    "        if emo == \"neutral\": continue\n",
    "        elif emo not in [\"anger\", \"joy\", \"sadness\", \"surprise\", \"disgust\", \"fear\"]:\n",
    "            print(\"  [{}/{}] Failed to process utterance {} due to invalid emotion {}\".format(i+1, len(convo), name, emo))\n",
    "            continue\n",
    "        if name in cause_eval_labelled: continue\n",
    "        \n",
    "        if i == 0:\n",
    "            pos = \"beg\"\n",
    "            window = get_window_beg(convo)\n",
    "        elif i == len(convo) - 1:\n",
    "            pos = \"end\"\n",
    "            window = get_window_end(convo)\n",
    "        else:\n",
    "            pos = \"mid\"\n",
    "            window = get_window_mid(convo, i)\n",
    "        \n",
    "        try:\n",
    "            window_str, diff = format_window((utt_idx, window), False)\n",
    "            window_str_labelled, diff = format_window((utt_idx, window), True)\n",
    "            closest_windows = db_dict[emo][pos].similarity_search(window_str)[1:4]\n",
    "            closest_indices = [wdw.page_content.split(\"\\n\")[0].strip() for wdw in closest_windows]\n",
    "            closest_windows = [cause_windows[idx] for idx in closest_indices]\n",
    "            window_batch = [{\"conversation\": window} for window in closest_windows]\n",
    "            explainations = explaination_pipeline.batch(window_batch, config={\"max_concurrency\": 3})        \n",
    "            examples = [closest_windows[i] + \"\\n\" +exp for i, exp in enumerate(explainations)]\n",
    "            scene = video_captions[str(conv_idx)]\n",
    "            out = cause_json_chain.invoke({\"window\": window_str_labelled,\n",
    "                                        \"scene\": scene,\n",
    "                                        \"example_1\": examples[0],\n",
    "                                        \"example_2\": examples[1],\n",
    "                                        \"example_3\": examples[2]})\n",
    "            causes = json.loads(out)[\"causes\"]\n",
    "            ecp = []\n",
    "            for c in causes:\n",
    "                ecp.append([f\"{utt_idx}_{emo}\", str(int(c)+diff)])\n",
    "            a[\"emotion-cause_pairs\"].extend(ecp)\n",
    "            cause_eval_labelled[name] = ecp   \n",
    "                \n",
    "            print(\"  [{}/{}] Processed utterance {}\".format(i+1, len(convo), name))\n",
    "            \n",
    "        except Exception as error:\n",
    "             print(\"  [{}/{}] Failed to process utterance {} due to {}\".format(i+1, len(convo), name, error))\n",
    "             \n",
    "    print(\"[{}/{}] Processed Conv {}\".format(k+1, len(anno), conv_idx))\n",
    "    if k % step == 0:\n",
    "        print(\"json dump...\")\n",
    "        json.dump(cause_eval_labelled, open(\"cause_eval_labelled.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b163c702-3dc6-44d2-9c19-875a6d9bca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(cause_eval_labelled, open(\"cause_eval_labelled.json\", \"w\"))\n",
    "json.dump(anno, open(\"cur_anno.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6bdfa-985d-4dd3-9aaf-6a83dc35d752",
   "metadata": {},
   "source": [
    "#### Postprocessing Causes to added self-causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a573270-f62f-439f-a5a5-a1f498bdd746",
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in anno:\n",
    "    same_ecp = []\n",
    "    for utt in convo[\"conversation\"]:\n",
    "        uid = utt[\"utterance_ID\"]\n",
    "        emo = utt[\"emotion\"]\n",
    "        if emo != \"neutral\":\n",
    "            same_ecp.append([str(uid)+\"_\"+emo, str(uid)])\n",
    "    for p in same_ecp:\n",
    "        if p not in convo[\"emotion-cause_pairs\"]:\n",
    "            convo[\"emotion-cause_pairs\"].append(p)\n",
    "\n",
    "json.dump(anno, open(\"cur_anno_same_added.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
