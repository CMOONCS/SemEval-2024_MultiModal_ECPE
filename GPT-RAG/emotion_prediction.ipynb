{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0496cca-3142-4cc5-beb4-5c16049e5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from key import OPENAI_KEY, LANGSMITH_KEY # Import your own keys\n",
    "from operator import itemgetter\n",
    "import time\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_KEY  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d373c4c-f791-457e-a212-4bc3e6ef2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = \"../data/text/Subtask_2_test.json\" # path to json file\n",
    "anno = json.load(open(text_dir))\n",
    "video_captions = json.load(open(\"eval_proc_out.json\")) # loading processed video captions\n",
    "explained_emotions = json.load(open(\"emotion_explainations.json\")) # loading explainations for train set conversations with all emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55ff83-4401-4dc5-913f-d13ee89cf8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.load_local(\"all_emotion_index\", embeddings)\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008e0a0-b04f-437d-9806-c94913ee771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [{\"conversation\": a[\"conversation\"], \"scene\": video_captions[str(a[\"conversation_ID\"])]} for a in anno]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1475c-d10b-428f-8aeb-a13c16bc419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_rag = \"\"\"\n",
    "You are a die-hard fan of the popular Friends TV show. \n",
    "You have all the knowledge of all the seasons and are familiar with all the characters. \n",
    "Your task is to recognize emotions in utterances. \n",
    "Here's an annotated example with recognized emotion and explanation:\n",
    "\n",
    "{example}\n",
    "\n",
    "Like above example annotate the following Conversation:\n",
    "Context for the scene is given below:\n",
    "{scene}\n",
    "\n",
    "Conversation:\n",
    "{conversation}\n",
    "\n",
    "Classify the emotional state of the speaker in each utterance into ONLY one out of the 6 emotions:\n",
    "Anger, Disgust, Fear, Joy, Sadness, Surprise. \n",
    "The emotion of the speaker is determined by the context of the conversation. \n",
    "Give explanation for your classification using the context. Only Use the above 6 emotion categories. \n",
    "If the emotion is not in any category, is a mix of several categories, or is ambiguous, \n",
    "classify the state as \"Neutral\".  Sarcastic comments may be categorized as Neutral.\n",
    "Format the output as JSON as the given example. No plain text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1eac4-00fa-4cdf-a719-625896aee2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_convo(convo):\n",
    "    out = \"\"\n",
    "    for i, utt in enumerate(convo):\n",
    "        out += f'\\n{i+1}. {utt[\"speaker\"]}: {utt[\"text\"]}'\n",
    "    return out\n",
    "\n",
    "def to_json(d):\n",
    "    return json.dumps(d)\n",
    "    \n",
    "def retrieve_example(convo):\n",
    "    conv_string = format_convo(convo)\n",
    "    closest = db.similarity_search(conv_string)\n",
    "    closest_idx = closest[0].page_content.split(\"\\n\")[0].strip()\n",
    "    closest_convo = explained_emotions[closest_idx]\n",
    "    return json.dumps(closest_convo)\n",
    "\n",
    "emotion_rag_prompt = ChatPromptTemplate.from_template(emotion_rag)\n",
    "\n",
    "emotion_pipeline = (\n",
    "    {\"conversation\": itemgetter(\"conversation\") | RunnableLambda(to_json),\n",
    "     \"example\": itemgetter(\"conversation\") | RunnableLambda(retrieve_example),\n",
    "     \"scene\": itemgetter(\"scene\")}\n",
    "    | emotion_rag_prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e033f-e182-4b1b-b449-82280ad36f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_eval_labelled = {}\n",
    "# emotion_eval_labelled = json.load(open(\"emotion_eval_labelled.json\")) # if resuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647323f-329f-4af1-b4da-e48a9adb6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep repeating untill all the conversations are processed sucessfully\n",
    "save_step = 10\n",
    "for i, a in enumerate(anno):\n",
    "    conv_id = a[\"conversation_ID\"]\n",
    "    if str(conv_id) in emotion_eval_labelled or conv_id in emotion_eval_labelled: continue\n",
    "    batch = {\"conversation\": a[\"conversation\"], \"scene\": video_captions[str(conv_id)]}\n",
    "    out = emotion_pipeline.invoke(batch)\n",
    "    \n",
    "    try:\n",
    "        emotion_eval_labelled[conv_id] = {\"conversation_ID\": conv_id,\n",
    "                                        \"conversation\": json.loads(out)}\n",
    "        print(\"[{}/{}] Processed Conv {}\".format(i+1, len(anno), conv_id))\n",
    "    except:\n",
    "        print(\"[{}/{}] Failed to Process Conv {}\".format(i+1, len(anno), conv_id))\n",
    "              \n",
    "    if i%save_step == 0:\n",
    "        print(\"json dump...\")\n",
    "        json.dump(emotion_eval_labelled, open(\"emotion_eval_labelled.json\", \"w\"))\n",
    "    time.sleep(0.20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468100e8-5203-4f64-a8bc-d692fcbf3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(emotion_eval_labelled, open(\"emotion_eval_labelled.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
