{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d9f15-0ca2-4c3b-b3ba-4c6363182125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from key import OPENAI_KEY, LANGSMITH_KEY # Add your own keys\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345e53a-7b3f-4b4f-8b5f-18a08f1598ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = \"../data/text/Subtask_2_train.json\"\n",
    "anno = json.load(open(text_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdece19a-8924-4a64-bd96-7dc5baf28909",
   "metadata": {},
   "source": [
    "#### All Emotion Conversation Index\n",
    "- Finding such conversations in training set\n",
    "- Formatting them and getting explainations for emotion annotations\n",
    "- Saving explainations\n",
    "- Storing the conversations with all emotions in FAISS index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201f5f5-5273-456e-9f6e-8983656571a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"]\n",
    "idx = []\n",
    "for i, a in enumerate(anno):\n",
    "    e_flag = {e: False for e in emotions}\n",
    "    for utt in a[\"conversation\"]:\n",
    "        e_flag[utt[\"emotion\"]] = True\n",
    "    if sum(e_flag.values()) == len(emotions):\n",
    "        idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa5aac-c32c-4051-a830-3c9f4dae05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_convo(idx, conversation, emotion=False):\n",
    "    out = str(idx)\n",
    "    # out = \"\"\n",
    "    for i, utt in enumerate(conversation):\n",
    "        out += f'\\n{i+1}. {utt[\"speaker\"]}: {utt[\"text\"]}'\n",
    "        if emotion:\n",
    "            out += f' [{utt[\"emotion\"]}]'\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e6d23-c901-420f-84b9-aa6f577b968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_explaination_prompt = \"\"\"\n",
    "There are 6 basic emotions: Anger, Disgust, Fear, Joy, Sadness, Surprise. \n",
    "The emotion of the speaker is determined by the context of the conversation. \n",
    "If the emotion is not in any category, is a mix of several categories, or is ambiguous it can be categorized as \"Neutral\". \n",
    "\n",
    "Analyze the following conversation where emotion of each utterance is annotated in square brackets at the end. \n",
    "Give reasoning behind the annotation of each utterance.\n",
    "\n",
    "{conversation}\n",
    "\n",
    "Output a JSON in the following format:\n",
    "[{{\"utterance_ID\": id,\n",
    "  \"text\" : content,\n",
    "  \"speaker\": speaker\n",
    "  \"emotion\": emotion, \n",
    "  \"explanation\": detailed explanation}}\n",
    "  ...\n",
    "]\n",
    "No plain text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb2da0-d3ab-4cbd-a960-29d1112a3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(openai_api_key=OPENAI_KEY)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "emotion_explaination_prompt = ChatPromptTemplate.from_template(emotion_explaination_prompt)\n",
    "emotion_explaination_chain = emotion_explaination_prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25206012-1c01-4207-bd21-1f8dbc5c1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_convos = [format_convo(i, anno[i][\"conversation\"], True) for i in idx]\n",
    "batch = [{\"conversation\": convo} for convo in emo_convos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae84f82-e0b1-4e89-9b99-f9f5bfbb9de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = emotion_explaination_chain.batch(batch, config={\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a48c1-0756-4e00-8e11-a95d872b0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to fix a faulty json output from GPT\n",
    "def strip(s):\n",
    "    return re.sub('[^0-9a-zA-Z]+', '', s.strip())\n",
    "\n",
    "def fix_json(s):\n",
    "    emo_json = [] \n",
    "    cur_dict = {}\n",
    "    for line in s.split(\"\\n\"):\n",
    "        components = line.strip().split(\":\")\n",
    "        key = strip(components[0])\n",
    "        if key == \"utteranceID\":\n",
    "            if len(cur_dict) != 0:\n",
    "                emo_json.append(cur_dict)\n",
    "                cur_dict = {}\n",
    "            cur_dict[\"utterance_ID\"] = strip(components[1]) \n",
    "        elif key == \"text\":\n",
    "            cur_dict[key] = \":\".join(components[1:])\n",
    "        elif key == \"speaker\":\n",
    "            cur_dict[key] = strip(components[1])\n",
    "        elif key == \"emotion\":\n",
    "            cur_dict[key] = strip(components[1])\n",
    "        else:\n",
    "            cur_dict[key] = components[1].strip()[1:-3]\n",
    "    return emo_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc66673-bdac-41ba-9843-31938472a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_explain_dict = {}\n",
    "\n",
    "for i, k in enumerate(idx):\n",
    "    try:\n",
    "        v = json.loads(outs[i])\n",
    "    except:\n",
    "        v = fix_json(outs[i])\n",
    "    emo_explain_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c4a64-40a5-42c6-9f6c-07b43dd81c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(emo_explain_dict, open(\"emotion_explainations.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7596029-b4ff-4342-a505-40e6e2eb9a21",
   "metadata": {},
   "source": [
    "##### Creating FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7e98a-89a3-47c5-b713-7ae12cc9b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "all_emo_convos = [format_convo(i, anno[i][\"conversation\"], False) for i in idx]\n",
    "db = FAISS.from_texts(all_emo_convos, embeddings)\n",
    "db.save_local(\"all_emotion_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e84aec-444c-415c-9c07-d049a12b49bb",
   "metadata": {},
   "source": [
    "#### Cause Windows Index \n",
    "- Create windows based on the position of emotional utterance (beg, mid, end)\n",
    "- Create FAISS indices for three types of windows for each 6 emotions for RAG. (18 Indices in total)\n",
    "- Save the Cause Windows in JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92824693-fc6f-4973-b6ad-911b5b92d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_beg(convo: list, size:int = 3) -> list:\n",
    "    return deepcopy(convo[:size])\n",
    "\n",
    "def get_window_end(convo: list, size:int = 6) -> list:\n",
    "    return deepcopy(convo[-size:])\n",
    "\n",
    "def get_window_mid(convo:list, idx:int, prev_size:int = 5, next_size:int = 2) -> list:\n",
    "    return deepcopy(convo[max(0, idx-prev_size) : (idx+1) + next_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421c7e7-0074-4a62-913b-f0a72ddd0e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"anger\", \"joy\", \"sadness\", \"surprise\", \"disgust\", \"fear\"]\n",
    "index_dict = {emo: {\"beg\": [], \"mid\": [], \"end\": []} for emo in emotions}\n",
    "\n",
    "for a in anno:\n",
    "    for i, utt in enumerate(a[\"conversation\"]):\n",
    "        if utt[\"emotion\"] != \"neutral\":\n",
    "            if i == 0:\n",
    "                index_dict[utt[\"emotion\"]][\"beg\"].append((utt[\"utterance_ID\"], \n",
    "                                                          get_window_beg(a[\"conversation\"]),\n",
    "                                                          utt[\"causes\"],\n",
    "                                                          utt[\"video_name\"].split(\".\")[0]))\n",
    "            elif i == len(a[\"conversation\"]) - 1:\n",
    "                index_dict[utt[\"emotion\"]][\"end\"].append((utt[\"utterance_ID\"], \n",
    "                                                          get_window_end(a[\"conversation\"]),\n",
    "                                                          utt[\"causes\"],\n",
    "                                                          utt[\"video_name\"].split(\".\")[0]))\n",
    "            else:\n",
    "                index_dict[utt[\"emotion\"]][\"mid\"].append((utt[\"utterance_ID\"], \n",
    "                                                          get_window_mid(a[\"conversation\"], i),\n",
    "                                                          utt[\"causes\"],\n",
    "                                                          utt[\"video_name\"].split(\".\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb4019-435a-4c4c-a09d-206f95780cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_window(window: tuple, label:bool = False) -> str:\n",
    "    idx, window, causes, name = window\n",
    "    utt_idx = idx\n",
    "    emo = None\n",
    "    out_str = \"\"\n",
    "    if not label:\n",
    "        out_str += f\"{name}\\n\"\n",
    "    for i, utt in enumerate(window):\n",
    "        if idx == utt[\"utterance_ID\"]:\n",
    "            emo = utt[\"emotion\"]\n",
    "            out_str += f'{i+1}. {utt[\"speaker\"]}: {utt[\"text\"]}'\n",
    "            if label: out_str += f' [{emo}]\\n'\n",
    "            else: out_str += '\\n'\n",
    "            utt_idx = i+1\n",
    "        else:\n",
    "            out_str += f'{i+1}. {utt[\"speaker\"]}: {utt[\"text\"]}\\n'\n",
    "    return out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9cafd8-d905-40d0-9b54-d19270848505",
   "metadata": {},
   "outputs": [],
   "source": [
    "for emo in emotions:\n",
    "    for pos in [\"beg\", \"mid\", \"end\"]:\n",
    "        window_strings = [format_window(window) for window in index_dict[emo][pos]]\n",
    "        db = FAISS.from_texts(window_strings, embeddings)\n",
    "        db.save_local(f\"cause_windows/{emo}/{pos}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18231791-5e31-444a-926a-fc9bafcc8c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_windows = {}\n",
    "\n",
    "for emo in emotions:\n",
    "    for pos in [\"beg\", \"mid\", \"end\"]:\n",
    "        for window in index_dict[emo][pos]:\n",
    "            window_str = format_window(window, True)\n",
    "            idx, wdw, cs, name = window\n",
    "            cause_windows[name] = window_str\n",
    "\n",
    "json.dump(cause_windows, open(\"cause_windows.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
