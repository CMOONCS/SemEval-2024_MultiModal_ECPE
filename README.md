# SemiEval-2024_MultiModal_ECPE
## Unimodal ECE/ECPE
- [Chen, F., Shi, Z., Yang, Z., & Huang, Y. (2022). Recurrent synchronization network for emotion-cause pair extraction. Knowledge-Based Systems, 238, 107965.](https://www.sciencedirect.com/science/article/pii/S0950705121010923)

- [Huang, W., Yang, Y., Huang, X., Peng, Z., & Xiong, L. (2023). Emotion-cause pair extraction based on interactive attention. Applied Intelligence, 53(9), 10548-10558.](https://link.springer.com/article/10.1007/s10489-022-03873-x)

- [Yu, J., Liu, W., He, Y., & Zhong, B. (2022). A Hierarchical Heterogeneous Graph Attention Network for Emotion-Cause Pair Extraction. Electronics, 11(18), 2884.](https://www.mdpi.com/2079-9292/11/18/2884)

- [Cao, Q., Hao, X., Ren, H., Xu, W., Xu, S., & Asiedu, C. J. (2022). Graph attention network based detection of causality for textual emotion-cause pair. World Wide Web, 1-15.](https://link.springer.com/article/10.1007/s11280-022-01111-5)

- [Yuan, C., Fan, C., Bao, J., & Xu, R. (2020, November). Emotion-cause pair extraction as sequence labeling based on a novel tagging scheme. In Proceedings of the 2020 conference on empirical methods in natural language processing (EMNLP) (pp. 3568-3573).](https://aclanthology.org/2020.emnlp-main.289.pdf)

- [Chen, Y., Hou, W., Li, S., Wu, C., & Zhang, X. (2020, December). End-to-end emotion-cause pair extraction with graph convolutional network. In Proceedings of the 28th International Conference on Computational Linguistics (pp. 198-207).](https://aclanthology.org/2020.coling-main.17.pdf)

- [Fan, C., Yuan, C., Du, J., Gui, L., Yang, M., & Xu, R. (2020, July). Transition-based directed graph construction for emotion-cause pair extraction. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (pp. 3707-3717).](https://aclanthology.org/2020.acl-main.342.pdf)

- [Wang, Y., Li, Y., Yu, K., & Hu, Y. (2023, May). Knowledge-Enhanced Hierarchical Transformers for Emotion-Cause Pair Extraction. In Pacific-Asia Conference on Knowledge Discovery and Data Mining (pp. 112-123). Cham: Springer Nature Switzerland.](https://link.springer.com/chapter/10.1007/978-3-031-33383-5_9)

- [Chen, F., Shi, Z., Yang, Z., & Huang, Y. (2022). Recurrent synchronization network for emotion-cause pair extraction. Knowledge-Based Systems, 238, 107965.](https://www.sciencedirect.com/science/article/pii/S0950705121010923)

- [Jeong, D., & Bak, J. (2023, May). Conversational Emotion-Cause Pair Extraction with Guided Mixture of Experts. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics (pp. 3280-3290).](https://aclanthology.org/2023.eacl-main.240.pdf)

- [Cheng, Z., Jiang, Z., Yin, Y., Wang, C., Ge, S., & Gu, Q. (2023). A consistent dual-mrc framework for emotion-cause pair extraction. ACM Transactions on Information Systems, 41(4), 1-27.](https://dl.acm.org/doi/10.1145/3558548)

- [Fan, W., Zhu, Y., Wei, Z., Yang, T., Ip, W. H., & Zhang, Y. (2021). Order-guided deep neural network for emotion-cause pair prediction. Applied Soft Computing, 112, 107818.](https://www.sciencedirect.com/science/article/pii/S1568494621007390)

- [Xing, B., & Tsang, I. W. (2023). Co-evolving Graph Reasoning Network for Emotion-Cause Pair Extraction. arXiv preprint arXiv:2306.04340.](https://arxiv.org/pdf/2306.04340.pdf)

- [Bhat, A., & Modi, A. (2023, January). Multi-task learning framework for extracting emotion cause span and entailment in conversations. In Transfer Learning for Natural Language Processing Workshop (pp. 33-51). PMLR.](https://proceedings.mlr.press/v203/bhat23a/bhat23a.pdf)

- 

## Multimodal ECE/ECPE :tada:
- [Joshi, A., Bhat, A., Jain, A., Singh, A. V., & Modi, A. (2022). COGMEN: COntextualized GNN based multimodal emotion recognition. arXiv preprint arXiv:2205.02455.](https://aclanthology.org/2022.naacl-main.306.pdf) :shipit:

- [Wang, F., Ding, Z., Xia, R., Li, Z., & Yu, J. (2021). Multimodal emotion-cause pair extraction in conversations. arXiv preprint arXiv:2110.08020.](https://arxiv.org/pdf/2110.08020.pdf)

- [Zheng, W., Yu, J., Xia, R., & Wang, S. (2023, July). A Facial Expression-Aware Multimodal Multi-task Learning Framework for Emotion Recognition in Multi-party Conversations. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 15445-15459).](https://aclanthology.org/2023.acl-long.861.pdf)

- [Zhou, J., Li, F., Teng, C., Liu, Y., Xiang, C., & Ji, D. (2023). MOIT: A Novel task for mining opinions towards implicit targets. Engineering Applications of Artificial Intelligence, 126, 106841.](https://www.sciencedirect.com/science/article/pii/S0952197623010254)

## MultiModal Graph-Based Emotion Recognition 
- [Zhang, X., & Li, Y. (2023). A Cross-Modality Context Fusion and Semantic Refinement Network for Emotion Recognition in Conversation. Annual Meeting of the Association for Computational Linguistics.](https://www.aclanthology.org/2023.acl-long.732.pdf)

- [Joshi, A., Bhat, A., Jain, A., Singh, A. V., & Modi, A. (2022). COGMEN: COntextualized GNN based multimodal emotion recognition. arXiv preprint arXiv:2205.02455.](https://aclanthology.org/2022.naacl-main.306.pdf)

- [Hu, D., Hou, X., Wei, L., Jiang, L., & Mo, Y. (2022). MM-DFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations. ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 7037-7041.](https://arxiv.org/pdf/2203.02385.pdf)

- [Fu, Y., Okada, S., Wang, L., Guo, L., Song, Y., Liu, J., & Dang, J. (2022). Context- and Knowledge-Aware Graph Convolutional Network for Multimodal Emotion Recognition. IEEE MultiMedia, 29, 91-100.](https://ieeexplore.ieee.org/document/9772497)

- [Hu, J., Liu, Y., Zhao, J., & Jin, Q. (2021). MMGCN: Multimodal Fusion via Deep Graph Convolution Network for Emotion Recognition in Conversation. ArXiv, abs/2107.06779.](https://arxiv.org/pdf/2107.06779.pdf)

- [Fu, Y., Okada, S., Wang, L., Guo, L., Song, Y., Liu, J., & Dang, J. (2021). CONSK-GCN: Conversational Semantic- and Knowledge-Oriented Graph Convolutional Network for Multimodal Emotion Recognition. 2021 IEEE International Conference on Multimedia and Expo (ICME), 1-6.](https://ieeexplore.ieee.org/document/9428438)

- [Li, J., Wang, X., Lv, G., & Zeng, Z. (2022). GraphMFT: A Graph Attention based Multimodal Fusion Technique for Emotion Recognition in Conversation. arXiv preprint arXiv:2208.00339.](https://arxiv.org/pdf/2208.00339.pdf)

## Unimodal Graph-Based ECE/ECPE

- [Cao, Q., Hao, X., Ren, H. et al. Graph attention network based detection of causality for textual emotion-cause pair. World Wide Web 26, 1731–1745 (2023).](https://link.springer.com/article/10.1007/s11280-022-01111-5#Sec1)

- [Yan, H., Gui, L., Pergola, G., & He, Y. (2021). Position bias mitigation: A knowledge-aware graph model for emotion cause extraction. arXiv preprint arXiv:2106.03518.](https://arxiv.org/pdf/2106.03518.pdf)

- [Zhao, W., Zhao, Y., Li, Z., & Qin, B. (2022). Knowledge-Bridged Causal Interaction Network for Causal Emotion Entailment. AAAI Conference on Artificial Intelligence.](https://arxiv.org/pdf/2212.02995.pdf)
  
- [Xiangju Li, Wei Gao, Shi Feng, Daling Wang, and Shafiq Joty. 2021. Span-Level Emotion Cause Analysis by BERT-based Graph Attention Network. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management (CIKM '21). Association for Computing Machinery, New York, NY, USA, 3221–3226.](https://dl.acm.org/doi/pdf/10.1145/3459637.3482185)

- [Zheng, L., Ji, D., Li, F., Fei, H., Wu, S., Li, J., ... & Teng, C. (2023). ECQED: Emotion-Cause Quadruple Extraction in Dialogs. arXiv preprint arXiv:2306.03969.](https://arxiv.org/pdf/2306.03969.pdf)

## Others

- Emotion Recognition in Conversations [GitHub](https://github.com/declare-lab/conv-emotion)

- MuTEC: An end to end Multi-Task learning framework for extractingEmotions and emotion Cause in conversations [GitHub](https://github.com/Exploration-Lab/MuTEC)
  
- [Kong, D., Yu, N., Yuan, Y., Fu, G., & Gong, C. (2022). Discourse-Aware Emotion Cause Extraction in Conversations. arXiv preprint arXiv:2210.14419.](https://arxiv.org/pdf/2210.14419.pdf)

- [Riyadh, M., & Shafiq, M. O. (2022, December). Towards Emotion Cause Generation in Natural Language Processing using Deep Learning. In 2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA) (pp. 140-147). IEEE.](https://ieeexplore.ieee.org/abstract/document/10069911)

- [Yang, X., Feng, S., Zhang, Y., & Wang, D. (2021, August). Multimodal sentiment detection based on multi-channel graph neural networks. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (pp. 328-339).](https://aclanthology.org/2021.acl-long.28.pdf)
- [Ahmed, N., Al Aghbari, Z., & Girija, S. (2023). A systematic survey on multimodal emotion recognition using learning algorithms. Intelligent Systems with Applications, 17, 200171](https://www.sciencedirect.com/science/article/pii/S2667305322001089/pdf)
